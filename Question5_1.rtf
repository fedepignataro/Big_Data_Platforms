{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 1. Run this to create the input directory\
hdfs dfs -mkdir -p /question5_1/input\
\
2. Use wget to download the files needed, putting them in the directory.\
\
wget http://www.textfiles.com/etext/FICTION/defoe-robinson-103.txt\
hdfs dfs -copyFromLocal defoe-robinson-103.txt /question5_1/input\
\
wget http://www.textfiles.com/etext/FICTION/callwild\
hdfs dfs -copyFromLocal callwild /question5_1/input\
\
3. Run 1st round (copy-paste in order to respect spaces)\
hadoop jar ../hadoop-streaming-2.8.1.jar -input question5_1/input -output question5_1/out_round1 -file ./Map1.py -mapper Map1.py -file ./Reduce1.py -reducer Reduce1.py\
\
4. Run 2nd round (copy-paste in order to respect spaces)\
hadoop jar ../hadoop-streaming-2.8.1.jar -input question5_1/out_round1 -output question5_1/out_round2 -file ./Map2.py -mapper Map2.py -file ./Reduce2.py -reducer Reduce2.py\
\
5. Run 3rd round (copy-paste in order to respect spaces)\
hadoop jar ../hadoop-streaming-2.8.1.jar -input question5_1/out_round2 -output question5_1/out_round3 -file ./Map3.py -mapper Map3.py -file ./Reduce3.py -reducer Reduce3.py\
\
hdfs dfs -get question5_1\
\
cat ./question5_1/out_round3/part-00000 | python top.py}
{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 1. Create input directory\
hdfs dfs -mkdir -p question5_2/input\
\
2. Copy epinions file into hadoop files\
hdfs dfs -copyFromLocal soc-Epinions1.txt question5_2/input\
\
3 Here, we convert the initial data into something we are able to use as Pagerank algorithm\
hadoop jar ../hadoop-streaming-2.8.1.jar -input question5_2/input/soc-Epinions1.txt -output question5_2/out_round_1 -file ./SetupMapper.py -mapper SetupMapper.py\
\
4. Run this algorithm many times:\
declare -i n\
n=10\
for i in $(seq 1 10);\
do\
    hadoop jar ../hadoop-streaming-2.8.1.jar -input question5_2/out_round_$i -output question5_2/out_round_$((i+1)) -file ./Map.py -mapper Map.py -file ./Reduce.py -reducer Reduce.py\
done\
\
hdfs dfs -get question5_2/out_round_$((n+1))\
\
cat ./question5_2/out_round_$((n+1)) | python get_highest.py}